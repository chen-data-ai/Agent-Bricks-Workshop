{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93af884f-b5d9-49a8-a735-12db2c1610d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Get started immediately with your Data with AI Functions\n",
    "\n",
    "We have a number of AI Functions designed as SQL functions that you can use in a SQL cell or SQL editor and use LLMs directly on your data immediately\n",
    "\n",
    "1. ai_analyze_sentiment\n",
    "2. ai_classify\n",
    "3. ai_extract\n",
    "4. ai_fix_grammar\n",
    "5. ai_gen\n",
    "6. ai_mask\n",
    "7. ai_similarity\n",
    "8. ai_summarize\n",
    "9. ai_translate\n",
    "10. ai_query\n",
    "11. ai_parse_document\n",
    "\n",
    "We will run a demo of a few of these functions below. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efe2fe72-432e-4462-ba55-aae650769735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca6fbd1a-c587-465d-9fbc-451610be4dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "dbutils.widgets.text(\"catalog_name\", catalog_name)\n",
    "dbutils.widgets.text(\"schema_name\", schema_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98d3d28d-348c-49db-8318-c448632e7bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demo Overview\n",
    "For today's demo, weâ€™re using a telecom dataset with the ultimate goal of creating a customer representative agent. One of the first steps in building any agent is data preparation. \n",
    "In this notebook, we will see how to leverage AI functions to clean, extract, and turn unstructured data into readily usable data by our agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3add0caf-3df9-4feb-83f5-e3b8cc06a7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ai_query\n",
    "The ai_query() function allows you to query machine learning models and large language models served using Mosaic AI Model Serving. To do so, this function invokes an existing Mosaic AI Model Serving endpoint and parses and returns its response. Databricks recommends using ai_query with Model Serving for batch inference. We can switch models depending on what we are trying to do. \n",
    "\n",
    "Documentation: https://docs.databricks.com/en/large-language-models/ai-functions.html#ai_query\n",
    "\n",
    "In this example, we'll assign priority to support tickets to help teams/agents take next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc9b0e88-6746-4e8f-9a41-d7a731e26de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "SELECT\n",
    "  `description`,   -- Placeholder for the input column\n",
    "  ai_query(\n",
    "    'databricks-meta-llama-3-1-8b-instruct', -- 'databricks-meta-llama-3-3-70b-instruct'\n",
    "    CONCAT(format_string('Analyze the support ticket and assign priority. The output must only be one word from this list: [low, medium, high, critical]. Do not add any extra text. Ticket: '), `description`)    -- Placeholder for the prompt and input\n",
    "  ) AS ai_priority  -- Placeholder for the output column\n",
    "FROM identifier(:catalog_name||'.'||:schema_name||'.'||'support_tickets')\n",
    "limit 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e6f3373-6291-4d1d-a19b-e4acfa7edafc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ai_parse_document\n",
    "\n",
    "The ai_parse_document() function invokes a state-of-the-art generative AI model from Databricks Foundation Model APIs to extract structured content from unstructured documents. The following file formats are supported:\n",
    "\n",
    "- PDF\n",
    "- JPG / JPEG\n",
    "- PNG\n",
    "- DOC/DOCX\n",
    "- PPT/PPTX\n",
    "\n",
    "Documentation: https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_parse_document \n",
    "\n",
    "Let's see an example extracting info from a sample customer invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a5e757-df5d-4539-b0b4-b6b7da1db206",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 7"
    }
   },
   "outputs": [],
   "source": [
    "WITH parsed_invoice AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    content\n",
    "  FROM\n",
    "    READ_FILES('/Volumes/'||:catalog_name||'/'||:schema_name||'/invoice', format => 'binaryFile')\n",
    ")\n",
    "SELECT\n",
    "  path,\n",
    "  ai_parse_document(content) AS parsed\n",
    "FROM\n",
    "  parsed_invoice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5507fc1d-3005-43ce-a3da-16b7c9d9d4c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's parse the extracted content further to create structured data to use for downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec781fd1-b05b-4f38-9bcd-bde38920eb24",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"extracted_fields\":272,\"summary\":441},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770396206486}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Cell 8"
    }
   },
   "outputs": [],
   "source": [
    "-- Parse raw data from invoice file\n",
    "WITH parsed_invoice AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    content\n",
    "  FROM\n",
    "    READ_FILES('/Volumes/'||:catalog_name||'/'||:schema_name||'/invoice', format => 'binaryFile')\n",
    "),\n",
    "raw_data AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    ai_parse_document(content) AS parsed\n",
    "  FROM\n",
    "    parsed_invoice\n",
    "),\n",
    "-- Step 2: Extract all text content from the parsed document\n",
    "extracted_content AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    -- Concatenate all text elements into full document text\n",
    "    concat_ws(\n",
    "      '\\n\\n',\n",
    "      transform(\n",
    "        filter(\n",
    "          try_cast(parsed:document:elements AS ARRAY<VARIANT>),\n",
    "          element -> try_cast(element:type AS STRING) IN ('text', 'section_header', 'title')\n",
    "        ),\n",
    "        element -> try_cast(element:content AS STRING)\n",
    "      )\n",
    "    ) AS full_text,\n",
    "    -- Extract tables separately (pricing, line items)\n",
    "    transform(\n",
    "      filter(\n",
    "        try_cast(parsed:document:elements AS ARRAY<VARIANT>),\n",
    "        element -> try_cast(element:type AS STRING) = 'table'\n",
    "      ),\n",
    "      element -> try_cast(element:content AS STRING)\n",
    "    ) AS tables,\n",
    "    -- Get page count\n",
    "    try_cast(parsed:document:page_count AS INT) AS page_count,\n",
    "    -- Check for errors\n",
    "    try_cast(parsed:error_status AS STRING) AS parse_error\n",
    "  FROM raw_data\n",
    ")\n",
    "\n",
    "Select \n",
    "  ai_extract(full_text, \n",
    "  array('Customer name', 'Customer address', 'Invoice number', 'Invoice date', 'Total amount')) as extracted_fields,\n",
    "  ai_query('databricks-meta-llama-3-1-8b-instruct', \n",
    "  CONCAT(format_string('Summarize the transaction details in 1 sentence. Transaction details: '), `full_text`)) as summary,\n",
    "  full_text, \n",
    "  tables\n",
    "from extracted_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "454c43fb-f85e-4314-9108-e275f28137e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Takeaway\n",
    "Many of our use cases simply need a reliable, out of the box solution to use AI. AI functions enable this for our customers and ai_query helps scale workloads. For more information on how to incorporate AI functions into your data engineering workflows, check out [Deploy batch inference pipelines](https://docs.databricks.com/aws/en/large-language-models/batch-inference-pipelines).  "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2,
    "widgetLayout": []
   },
   "notebookName": "01_AI functions",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
